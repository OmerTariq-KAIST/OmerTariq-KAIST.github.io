---
layout: default
title: Research
navbar_title: Research
---

<div class="row">
    <div class="col">
        <div class="card border-0 shadow-sm bg-white my-4">
            <div class="card-body p-5">
                <h2 class="card-title">Research Interests</h2>
                <hr>
                
                <div class="mb-5 row">
                    <div class="col-md-3">
                        <img data-src="/assets/images/research/foundation_models.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-9">
                        <h4><i class="fas fa-brain"></i> Foundation Models</h4>
                        <p>My research explores parameter-efficient fine-tuning techniques for large models, retrieval-augmented generation, in-context learning, and chain-of-thought reasoning. I'm particularly interested in vision-language models like CLIP and advancements in diffusion models and transformers for various applications.</p>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-3">
                        <img data-src="/assets/images/research/navigation.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-9">
                        <h4><i class="fas fa-map-marked-alt"></i> Navigation & Localization</h4>
                        <p>I develop neural inertial navigation systems, visual-inertial odometry frameworks, and end-to-end SLAM solutions. My work focuses on multi-modal sensor fusion for robust localization in challenging environments with applications in deep reinforcement learning and self-supervised learning paradigms.</p>
                        <div class="embed-responsive embed-responsive-16by9 mt-3">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/YOUR_NAVIGATION_VIDEO_ID" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-3">
                        <img data-src="/assets/images/research/hardware_aware.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-9">
                        <h4><i class="fas fa-microchip"></i> Hardware-Aware AI</h4>
                        <p>I work on neural architecture search, quantization techniques, and knowledge distillation to create efficient AI models. My research incorporates hardware-aware optimization, adversarial robustness considerations, differential privacy, and approaches for federated and distributed learning with FPGA/SoC acceleration.</p>
                        <video class="w-100 mt-3" controls>
                            <source src="/assets/videos/hardware_aware_demo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-3">
                        <img data-src="/assets/images/research/embodied_ai.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-9">
                        <h4><i class="fas fa-robot"></i> Embodied AI</h4>
                        <p>My research investigates vision-language-action models like PaLM-E, multimodal perception for robotic control, and sim-to-real transfer techniques to bridge virtual and physical environments for embodied AI agents.</p>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-3">
                        <img data-src="/assets/images/research/zero_shot.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-9">
                        <h4><i class="fas fa-bolt"></i> Zero-Shot and Few-Shot Learning</h4>
                        <p>I explore meta-learning approaches, prompt engineering techniques, cross-modal transfer methods, and low-resource adaptation strategies to enable AI systems to perform effectively with minimal training examples.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card border-0 shadow-sm bg-white my-4">
            <div class="card-body p-5">
                <h2 class="card-title">Current Projects</h2>
                <hr>
                
                <div class="mb-5 row">
                    <div class="col-md-4">
                        <img data-src="/assets/images/projects/nanomst.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-8">
                        <h4>NanoMST: Ultra-Lightweight Multiscale Transformer for TinyML</h4>
                        <p>Designing a hardware-aware multiscale transformer network optimized for TinyML applications, specifically targeting inertial motion tracking on resource-constrained devices. This project focuses on maintaining high accuracy while drastically reducing model size and computational requirements.</p>
                        <div class="embed-responsive embed-responsive-16by9 mt-3">
                            <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/YOUR_NANOMST_VIDEO_ID" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-4">
                        <img data-src="/assets/images/projects/deepils.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-8">
                        <h4>DeepILS: Domain-Invariant Inertial Localization System</h4>
                        <p>Developing an AIoT-enabled inertial localization system that maintains accuracy across varied environments without requiring environment-specific training. This work combines advanced deep learning techniques with domain adaptation to create robust positioning solutions.</p>
                        
                        <!-- Visualization Gallery -->
                        <div class="row mt-3">
                            <div class="col-md-6 mb-3">
                                <img data-src="/assets/images/visualizations/deepils_viz1.jpg" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png">
                            </div>
                            <div class="col-md-6 mb-3">
                                <img data-src="/assets/images/visualizations/deepils_viz2.jpg" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png">
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-4">
                        <img data-src="/assets/images/projects/convxformer.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-8">
                        <h4>ConvXformer: Privacy-Preserving Hybrid Architecture</h4>
                        <p>Creating a differentially private hybrid ConvNeXt-Transformer architecture for inertial navigation that balances accuracy with strong privacy guarantees. This work addresses the critical need for privacy-preserving AI in navigation applications.</p>
                        <video class="w-100 mt-3" controls>
                            <source src="/assets/videos/convxformer_demo.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                </div>
                
                <div class="mb-5 row">
                    <div class="col-md-4">
                        <img data-src="/assets/images/projects/federated.jpg" class="lazy w-100 rounded-sm img-hover" src="/assets/images/empty_300x200.png">
                    </div>
                    <div class="col-md-8">
                        <h4>Personalized Federated Learning for Neural Inertial Localization</h4>
                        <p>Implementing a model-agnostic meta-learning approach to personalize federated learning models for inertial localization, enabling quick adaptation to individual movement patterns and device characteristics while maintaining privacy.</p>
                        
                        <!-- Interactive Diagram (embedded as an image) -->
                        <div class="mt-3">
                            <img data-src="/assets/images/visualizations/federated_learning_diagram.jpg" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>